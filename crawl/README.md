# ğŸ—ï¸ News Crawler System

Há»‡ thá»‘ng crawl tin tá»©c tá»« nhiá»u trang web khÃ¡c nhau vÃ  lÆ°u vÃ o Supabase database.

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
crawl_news/
â”œâ”€â”€ ğŸ“ crawlers/           # Chá»©a táº¥t cáº£ cÃ¡c crawler
â”‚   â”œâ”€â”€ fireant_crawler.py      # Crawler FireAnt (stock + general)
â”‚   â”œâ”€â”€ cafef_keyword_crawler.py # Crawler CafeF vá»›i tá»« khÃ³a
â”‚   â”œâ”€â”€ cafef_general_crawler.py # Crawler CafeF tá»•ng quÃ¡t
â”‚   â”œâ”€â”€ chungta_crawler.py       # Crawler ChungTa
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“ config/             # CÃ¡c file cáº¥u hÃ¬nh
â”‚   â”œâ”€â”€ database_config.py       # Cáº¥u hÃ¬nh Supabase database
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“ utils/              # Tiá»‡n Ã­ch (chÆ°a sá»­ dá»¥ng)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“ logs/               # Log files
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ main_crawl_news.py     # File chÃ­nh Ä‘á»ƒ cháº¡y táº¥t cáº£ crawler
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ PROJECT_STRUCTURE.md   # HÆ°á»›ng dáº«n cáº¥u trÃºc dá»± Ã¡n
â””â”€â”€ README.md             # File nÃ y
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### Cháº¡y táº¥t cáº£ crawler
```bash
python main_crawl_news.py
```

### Cháº¡y má»™t crawler cá»¥ thá»ƒ
```bash
python main_crawl_news.py --single fireant_fpt
python main_crawl_news.py --single cafef_keyword
python main_crawl_news.py --single chungta
```

### Xem danh sÃ¡ch crawler
```bash
python main_crawl_news.py --list
```

## ğŸ› ï¸ CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh database
Kiá»ƒm tra file `config/database_config.py` Ä‘á»ƒ Ä‘áº£m báº£o thÃ´ng tin Supabase Ä‘Ãºng.

### 3. Cháº¡y crawler
```bash
python main_crawl_news.py
```

## ğŸ“Š CÃ¡c crawler cÃ³ sáºµn

1. **FireAnt FPT Stock** (`fireant_fpt`)
   - Crawl tin tá»©c cá»• phiáº¿u FPT tá»« FireAnt
   - LÆ°u vÃ o báº£ng `Crawl_news`

2. **FireAnt General** (`fireant_general`)
   - Crawl tin tá»©c tá»•ng quÃ¡t tá»« FireAnt
   - LÆ°u vÃ o báº£ng `General_News`

3. **CafeF Keyword** (`cafef_keyword`)
   - Crawl tin tá»©c theo tá»« khÃ³a tá»« CafeF
   - TÃ¬m kiáº¿m máº·c Ä‘á»‹nh: "FPT"

4. **CafeF General** (`cafef_general`)
   - Crawl tin tá»©c chung tá»« CafeF
   - Scroll vÃ  thu tháº­p nhiá»u bÃ i viáº¿t

5. **ChungTa News** (`chungta`)
   - Crawl tin tá»©c tá»« ChungTa.vn
   - Thu tháº­p bÃ i viáº¿t má»›i nháº¥t

## ğŸ“ Log files

Táº¥t cáº£ log Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c `logs/` vá»›i format:
```
logs/crawl_log_YYYYMMDD_HHMMSS.log
```

## âš™ï¸ Cáº¥u hÃ¬nh

- **MAX_SCROLLS**: Sá»‘ láº§n scroll tá»‘i Ä‘a (máº·c Ä‘á»‹nh: 20)
- **Database**: Supabase PostgreSQL
- **Selenium**: Chrome WebDriver vá»›i headless mode

## ğŸ”§ Troubleshooting

### Lá»—i import module
```bash
pip install -r requirements.txt
```

### Lá»—i ChromeDriver
Äáº£m báº£o Chrome browser Ä‘Ã£ cÃ i Ä‘áº·t vÃ  ChromeDriver tÆ°Æ¡ng thÃ­ch.

### Lá»—i database connection
Kiá»ƒm tra thÃ´ng tin Supabase URL vÃ  API key trong `config/database_config.py`.

## ğŸ“ˆ Future Improvements

- [ ] ThÃªm crawler cho cÃ¡c trang tin tá»©c khÃ¡c
- [ ] Implement retry mechanism
- [ ] ThÃªm email notification khi crawl xong
- [ ] Dashboard Ä‘á»ƒ monitor crawling status
- [ ] API Ä‘á»ƒ trigger crawling remotely
